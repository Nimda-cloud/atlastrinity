# Синхронізовано: 2026-01-31 (v5.0 - Optimized Config Templates)

# =============================================================================
# PROTOCOL DEFINITIONS
# =============================================================================
# Agent operational protocols define behavior rules for Atlas, Tetyana, Grisha.
# Protocols are loaded from: src/brain/data/protocols/
#
# Available Protocols:
# - data_protocol.txt          : Data processing and ingestion rules
# - sdlc_protocol.txt          : Software development (MANDATORY Vibe MCP usage)
# - search_protocol.txt        : Search strategies
# - storage_protocol.txt       : Memory and storage management
# - system_mastery_protocol.txt: System understanding
# - task_protocol.txt          : Task execution doctrine
# - voice_protocol.txt         : Voice communication (Ukrainian only)
# - vibe_docs.txt              : Vibe MCP documentation
# - create-new-program.md      : Project creation workflow
# - self-healing-protocol.md   : Autonomous recovery
# - system_monitoring_protocol.md: System state verification
#
# Protocols are loaded at startup via src/brain/mcp_registry.py
# =============================================================================

# =============================================================================
# GLOBAL MODEL CONFIGURATION
# =============================================================================
# Single source of truth for all models used across the system
# Change defaults here to switch models globally

models:
  # LLM Provider: "copilot" or "windsurf"
  # - copilot:  GitHub Copilot API (ghu_ token, all Copilot models)
  # - windsurf: Windsurf/Codeium API (sk-ws- token, FREE models only)
  #
  # When provider is "windsurf", models must be from the free tier:
  #   deepseek-v3, deepseek-r1, swe-1, swe-1.5, grok-code-fast-1,
  #   gpt-5.1-codex, gpt-5.1-codex-mini, kimi-k2.5, etc.
  #
  # Proxy: Both providers can work through a local proxy on port 8085:
  #   copilot:  python scripts/copilot_proxy.py
  #   windsurf: python scripts/windsurf_proxy.py
  provider: "copilot"                   # LLM provider: copilot | windsurf

  # Default models for different purposes
  # Using gpt-4o as default for GitHub Copilot API
  # You can change these to your preferred models (e.g., "claude-3.5-sonnet", "gpt-4o-mini", etc.)
  default: "gpt-4o"                    # Default LLM for agents
  vision: "gpt-4o"                     # Vision/multimodal tasks
  reasoning: "oswe-vscode-secondary"      # Raptor reasoning
  code_analysis: "grok-code-fast-1"      # Fast coding analysis
  consolidation: "oswe-vscode-secondary"          # Memory consolidation (Raptor native)
  
  # Fallbacks (used when primary unavailable)
  fallback: "gpt-4o"                   # Fallback model
  
  # Sandbox model (used by mcp_sandbox.py)
  sandbox: "oswe-vscode-secondary"

  # Agents inherit from models.default unless overridden

agents:
  atlas:
    # model: inherited from models.default 
    deep_model: "oswe-vscode-secondary"  # Raptor reasoning and planning
    temperature: 0.7
    max_tokens: 2000                 # Standard chat/task mode
    max_tokens_deep: 12000           # Deep persona mode (increased from 8000)

  tetyana:
    # model: inherited from models.default
    reasoning_model: "gpt-5-mini"       # Efficient routing and tool selection
    vision_model: ""             # Vision tasks, set in your config.yaml
    temperature: 0.5
    max_tokens: 2000

  grisha:
    # Three-Phase Verification Architecture:
    # Phase 1: Strategy planning (what to verify, which tools)
    strategy_model: "oswe-vscode-secondary" # Raptor reasoning for strategy
    
    # Phase 2: Tool selection & execution (MCP server interaction)
    # model: inherited from models.default
    
    # Phase 3: Result analysis & verdict
    vision_model: ""             # Vision/multimodal verification, set in your config.yaml
    verdict_model: "oswe-vscode-secondary"  # Raptor verdict reasoning
    
    # General settings
    temperature: 0.3
    max_tokens: 1500
    
    # Two-Phase Verification Sequential-Thinking (Quantum)
    verification_reasoning_model: "oswe-vscode-secondary" # Raptor verdict analysis
    verification_temperature: 0.2          # Low temp for precise reasoning
    verification_max_tokens: 4000          # Sufficient for deep analysis

# =============================================================================
# MCP SERVER CONFIGURATION
# =============================================================================
# Feature Flags Only.
# Detailed configuration (command, args, env) is in mcp_servers.json.

mcp_enhanced:
  retry_attempts: 3
  connection_timeout: 3600

mcp:
  # === TIER 1: MUST-HAVE (Ядро системи) ===
  macos_use:
    enabled: true

  filesystem:
    enabled: true

  sequential_thinking:
    enabled: true
    model: "oswe-vscode-secondary"   # Critical for complex reasoning

  # === TIER 2: HIGH PRIORITY (Рекомендовані) ===
  googlemaps:
    enabled: true

  vibe:
    enabled: true
    # Configuration is in vibe_config.toml

  memory:
    enabled: true

  graph:
    enabled: true

  redis:
    enabled: true

  duckduckgo_search:
    enabled: true

  golden_fund:
    enabled: true

  data_analysis:
    enabled: true

  github:
    enabled: true

  whisper_stt:
    enabled: true

  devtools:
    enabled: true

  # === TIER 3: ADDITIONAL (Додаткові) ===
  puppeteer:
    enabled: true

  # === TIER 4: SPECIALIZED (Спеціалізовані / Дебаг) ===
  chrome_devtools:
    enabled: true

  context7:
    enabled: true # External documentation server

# =============================================================================
# ORCHESTRATOR CONFIGURATION
# =============================================================================

orchestrator:
  # Timeouts
  task_timeout: 3600
  subtask_timeout: 120
  user_input_timeout: 20
  
  # Recursion control
  max_recursion_depth: 5
  
  # Verification
  validate_failed_steps_with_grisha: false  # Set to true to enable Auditor verification on fail
  recovery_voice_agent: atlas  # Which agent explains the recovery strategy

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

security:
  dangerous_commands:
    - rm -rf
    - mkfs
    - dd if=
    - ":(){ :|:& };:"
  require_confirmation: true

# =============================================================================
# SYSTEM PATHS
# =============================================================================
# Centralized path management for all system components

system:
  # Base directories
  config_root: ${CONFIG_ROOT}
  project_root: ${PROJECT_ROOT}
  home: ${HOME}
  
  # Application directories
  workspace_path: ${CONFIG_ROOT}/workspace
  logs: ${CONFIG_ROOT}/logs
  memory: ${CONFIG_ROOT}/memory
  screenshots: ${CONFIG_ROOT}/screenshots
  cache: ${CONFIG_ROOT}/cache
  temp: /tmp/atlastrinity
  
  # Repository paths
  repository_path: ${PROJECT_ROOT}
  backups: ${PROJECT_ROOT}/backups
  
  # Model directories
  models:
    tts: ${CONFIG_ROOT}/models/tts
    stt: ${CONFIG_ROOT}/models/faster-whisper
    stanza: ${CONFIG_ROOT}/models/stanza
    huggingface: ${CONFIG_ROOT}/models/huggingface

# =============================================================================
# API CONFIGURATION
# =============================================================================

api:
  timeout: 60
  retry_count: 3

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# Database configuration moved to database_management section below for centralized management

# =============================================================================
# STATE MANAGEMENT
# =============================================================================
# Redis URL configured in database_management.redis.url section below

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

logging:
  level: INFO
  max_log_size: 10485760
  backup_count: 5

# =============================================================================
# DATABASE MANAGEMENT CONFIGURATION
# =============================================================================

database_management:
  # SQLite configuration
  sqlite:
    url: sqlite+aiosqlite:///${CONFIG_ROOT}/atlastrinity.db
    
    # Connection settings
    connection:
      pool_size: 5
      pool_recycle: 3600
      echo: false                    # SQL query logging
      
    # Table management
    tables:
      sessions:
        enabled: true
        retention_days: 90           # Auto-delete sessions older than 90 days
        auto_archive: true
        
      tasks:
        enabled: true
        retention_days: 60
        auto_archive: true
        index_golden_path: true      # Index successful strategies
        
      logs:
        enabled: true
        retention_days: 30
        max_size_mb: 500             # Max total log size
        auto_cleanup: true
        
      conversation_summaries:
        enabled: true
        retention_days: 180
        compress_old: true
        
      agents:
        enabled: true
        track_performance: true
        
    # Access control
    access_control:
      read_only_mode: false
      allow_delete: true
      require_backup_before_delete: true
      
    # Backup settings
    backup:
      enabled: true
      auto_backup_on_shutdown: true
      auto_backup_frequency: daily   # daily | weekly | never
      backup_location: ${PROJECT_ROOT}/backups/databases
      max_backups: 7                 # Keep last 7 backups
      
  # ChromaDB (vector database) configuration
  chromadb:
    path: ${CONFIG_ROOT}/memory/chroma
    
    # Collection settings
    collections:
      atlastrinity_memory:
        enabled: true
        max_vectors: 100000
        distance_metric: cosine      # cosine | euclidean | l2
        
      conversations:
        enabled: true
        max_vectors: 50000
        retention_days: 180
        
      strategies:
        enabled: true
        max_vectors: 10000
        index_golden_path_only: true
        
    # Performance settings
    performance:
      batch_size: 100
      index_rebuild_threshold: 10000 # Rebuild index after N inserts
      cache_size_mb: 256
      
    # Access control
    access_control:
      read_only_mode: false
      allow_delete: true
      require_confirmation_on_clear: true
      
    # Backup settings - uses parent backup_location from SQLite section
    backup:
      enabled: true
      auto_backup_frequency: weekly
      max_backups: 4
      
  # Redis (state management) configuration
  redis:
    url: redis://localhost:6379/0
    
    # Connection settings
    connection:
      db: 0
      max_connections: 10
      socket_timeout: 5
      socket_connect_timeout: 5
      retry_on_timeout: true
      
    # Key namespaces and TTL
    namespaces:
      sessions:
        prefix: "session:"
        ttl_seconds: 86400           # 24 hours
        
      state:
        prefix: "state:"
        ttl_seconds: 7200            # 2 hours
        
      cache:
        prefix: "cache:"
        ttl_seconds: 3600            # 1 hour
        
      locks:
        prefix: "lock:"
        ttl_seconds: 300             # 5 minutes
        
    # Cleanup policy
    cleanup:
      enabled: true
      auto_cleanup_frequency: hourly # hourly | daily | never
      cleanup_expired_keys: true
      
    # Access control
    access_control:
      read_only_mode: false
      allow_flushdb: false           # Prevent accidental flush
      require_confirmation_on_clear: true
      
  # Global database settings
  global:
    # Data retention
    retention:
      enforce_global_retention: true
      min_retention_days: 7          # Minimum retention for any data
      max_retention_days: 365        # Maximum retention
      
    # Integrity checks
    integrity:
      auto_check_on_startup: true
      check_frequency: daily         # daily | weekly | never
      auto_repair: false             # Manual repair only
      
    # Migration settings
    migrations:
      auto_migrate: true             # Auto-apply schema migrations
      backup_before_migration: true
      rollback_on_failure: true
      
    # Monitoring
    monitoring:
      track_query_performance: true
      slow_query_threshold_ms: 1000
      log_slow_queries: true
      
      # Size limits
      max_db_size_gb: 10
      warn_at_size_gb: 8
      
    # Privacy and security
    security:
      encrypt_sensitive_fields: false # Encrypt API keys, tokens
      hash_passwords: true
      sanitize_logs: true            # Remove sensitive data from logs

voice:
  stt:
    model: large-v3                     # Whisper model (large-v3, medium, small)
    device: auto
    language: uk
  tts:
    engine: ukrainian-tts               # TTS engine
    device: cpu
    enabled: true
    force_ukrainian: true               # Forces translation of English text to Ukrainian
    interaction_language_guard: true    # Detects and warns about language mismatch

# =============================================================================
# MONITORING CONFIGURATION
# =============================================================================
# Settings for Prometheus, Grafana, and OpenSearch integration

monitoring:
  # Prometheus configuration
  prometheus:
    enabled: true
    port: 8001
    scrape_interval: 15s
    evaluation_interval: 15s
    
  # Grafana configuration
  grafana:
    enabled: true
    logging_format: json
    log_level: info
    
  # Storage configuration (Defaults to SQLite for standalone binary)
  # OpenSearch is optional for advanced server-based setups
  opensearch:
    enabled: false 
    hosts: ["http://localhost:9200"]
    index_prefix: "atlastrinity"
    
  # OpenTelemetry tracing configuration
  tracing:
    enabled: true
    service_name: "atlastrinity"
    otlp_endpoint: "localhost:4317"
    batch_timeout: 5s
    max_export_batch_size: 512
    
  # ETL Pipeline monitoring
  etl:
    enabled: true
    track_stages: ["scraping", "transformation", "distribution", "indexing"]
    error_thresholds:
      warning: 5
      critical: 10
      
  # Alerting rules (for future implementation)
  alerts:
    high_cpu_usage:
      threshold: 90
      duration: 5m
      severity: warning
      
    high_memory_usage:
      threshold: 85
      duration: 5m
      severity: warning
      
    request_failures:
      threshold: 10
      duration: 1m
      severity: critical
