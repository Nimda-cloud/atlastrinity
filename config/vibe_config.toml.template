# =============================================================================
# VIBE CLI CONFIGURATION
# =============================================================================
# Vibe is a code editor agent that uses LLM providers for code assistance
# Official documentation: https://docs.mistral.ai/mistral-vibe/introduction/configuration

# =============================================================================
# ACTIVE MODEL SELECTION
# =============================================================================
# Choose ONE active model based on your provider:
#
# === FOR COPILOT PROVIDER ===
# active_model = "gpt-4.1"           # Latest GPT-4 model
# active_model = "gpt-4o"            # GPT-4o (multimodal)
# active_model = "grok-code-fast-1"  # Fast coding analysis
#
# === FOR WINDSURF PROVIDER ===
# active_model = "deepseek-v3"       # Free general purpose
# active_model = "deepseek-r1"       # Free reasoning model
# active_model = "kimi-k2.5"         # Free coding model
#
# === FALLBACK CHAIN ===
# Models to try if active_model fails (in order)
fallback_chain = ["gpt-4.1", "gpt-4o", "deepseek-v3", "devstral-2"]

# Current selection (change based on your provider):
active_model = "gpt-4.1"


# System prompt ID (refers to file in ~/.vibe/prompts/ cli.md by default)
system_prompt_id = "cli"

# Default operational mode (default, plan, accept-edits, auto-approve)
default_mode = "auto-approve"

# Enable/Disable auto-updates
enable_auto_update = true

# Execution limits
max_turns = 100

# =============================================================================
# Tool Availability Patterns
# =============================================================================
# Exact names, glob patterns, or re: prefix for regex
enabled_tools = [] # Empty = all enabled
disabled_tools = [] # No tools disabled

# =============================================================================
# Provider Configuration
# =============================================================================
[[providers]]
name = "mistral"
api_base = "https://api.mistral.ai/v1"
api_key_env_var = "MISTRAL_API_KEY"
api_style = "mistral"
backend = "mistral"

[[providers]]
name = "openrouter"
api_base = "https://openrouter.ai/api/v1"
api_key_env_var = "OPENROUTER_API_KEY"
api_style = "openai"
backend = "generic"

[[providers]]
name = "copilot"
api_base = "http://127.0.0.1:8085"
api_key_env_var = "COPILOT_SESSION_TOKEN"
api_style = "openai"
backend = "generic"
requires_proxy = true
proxy_command = "python3 ${PROJECT_ROOT}/scripts/universal_proxy.py"
requires_token_exchange = true

[[providers]]
name = "windsurf"
api_base = "http://127.0.0.1:8085"
api_key_env_var = "WINDSURF_API_KEY"
api_style = "openai"
backend = "generic"
requires_proxy = true
proxy_command = "python3 ${PROJECT_ROOT}/scripts/universal_proxy.py"
requires_token_exchange = false

# =============================================================================
# Model Presets
# =============================================================================
[[models]]
name = "gpt-4o"
provider = "copilot"
alias = "gpt-4o"
temperature = 0.1
input_price = 0.0
output_price = 0.0

[[models]]
name = "oswe-vscode-secondary"
provider = "copilot"
alias = "raptor-mini"
temperature = 0.1
input_price = 0.0
output_price = 0.0

[[models]]
name = "gpt-5-mini"
provider = "copilot"
alias = "gpt-5-mini"
temperature = 0.1
input_price = 0.0
output_price = 0.0

[[models]]
name = "grok-code-fast-1"
provider = "copilot"
alias = "grok-code-fast-1"
temperature = 0.1
input_price = 0.0
output_price = 0.0

[[models]]
name = "gpt-4.1"
provider = "copilot"
alias = "gpt-4.1"
temperature = 0.1
input_price = 0.0
output_price = 0.0

# Windsurf models (FREE tier)
[[models]]
name = "deepseek-v3"
provider = "windsurf"
alias = "deepseek-v3"
temperature = 0.1
input_price = 0.0
output_price = 0.0

[[models]]
name = "deepseek-r1"
provider = "windsurf"
alias = "deepseek-r1"
temperature = 0.1
input_price = 0.0
output_price = 0.0

[[models]]
name = "swe-1.5"
provider = "windsurf"
alias = "swe-1.5"
temperature = 0.1
input_price = 0.0
output_price = 0.0

[[models]]
name = "kimi-k2.5"
provider = "windsurf"
alias = "kimi-k2.5"
temperature = 0.1
input_price = 0.0
output_price = 0.0

# =============================================================================
# Built-in Tool Permissions
# =============================================================================
# Per-mode permissions are defined in config/vibe/agents/*.toml.template:
#   plan.toml         — read-only tools auto, write/exec requires confirmation
#   accept-edits.toml — file tools auto, bash requires confirmation
#   auto-approve.toml — all tools auto-approved
#
# Fallback permissions when no agent mode is active:
[tools.read_file]
permission = "always"

[tools.grep]
permission = "always"

[tools.bash]
permission = "ask"

[tools.write_file]
permission = "ask"

[tools.search_replace]
permission = "ask"

# =============================================================================
# MCP Server Configuration (Optional)
# =============================================================================
# You can add [[mcp_servers]] here to extend Vibe's capabilities.

[[mcp_servers]]
name = "devtools"
transport = "stdio"
command = "python3"
args = ["-m", "src.mcp_server.devtools_server"]
env = { PYTHONPATH = "${PROJECT_ROOT}" }
description = "Developer Tools (Linter, Analysis, MCP Inspector CLI & Sandbox)"

# NOTE: Minimal MCP list by default to maximize TPM (Anti-Rate Limit).
